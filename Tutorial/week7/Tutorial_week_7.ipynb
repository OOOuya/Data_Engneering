{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe1c9906",
   "metadata": {},
   "source": [
    "# CS5481 - Tutorial 7\n",
    "## Recommendation system\n",
    "\n",
    "Welcome to CS5481 tutorial. In this tutorial, you will learn to utilize python to implement different recommendation methods.\n",
    "\n",
    "## preparation\n",
    "- Python\n",
    "- Python Libraries\n",
    "  - Matplotlib\n",
    "  - pands\n",
    "  - numpy\n",
    "  - sklearn\n",
    "  - os\n",
    "  - tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "801c695c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in d:\\common_app\\anaconda\\lib\\site-packages (3.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\common_app\\anaconda\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\common_app\\anaconda\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\common_app\\anaconda\\lib\\site-packages (from matplotlib) (8.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\common_app\\anaconda\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.16 in d:\\common_app\\anaconda\\lib\\site-packages (from matplotlib) (1.21.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\common_app\\anaconda\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: six in d:\\common_app\\anaconda\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Error parsing requirements for tensorflow-estimator: [Errno 2] No such file or directory: 'd:\\\\common_app\\\\anaconda\\\\lib\\\\site-packages\\\\tensorflow_estimator-2.3.0.dist-info\\\\METADATA'\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\common_app\\anaconda\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in d:\\common_app\\anaconda\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in d:\\common_app\\anaconda\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\common_app\\anaconda\\lib\\site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\common_app\\anaconda\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Error parsing requirements for tensorflow-estimator: [Errno 2] No such file or directory: 'd:\\\\common_app\\\\anaconda\\\\lib\\\\site-packages\\\\tensorflow_estimator-2.3.0.dist-info\\\\METADATA'\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in d:\\common_app\\anaconda\\lib\\site-packages (1.21.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Error parsing requirements for tensorflow-estimator: [Errno 2] No such file or directory: 'd:\\\\common_app\\\\anaconda\\\\lib\\\\site-packages\\\\tensorflow_estimator-2.3.0.dist-info\\\\METADATA'\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in d:\\common_app\\anaconda\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\common_app\\anaconda\\lib\\site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\common_app\\anaconda\\lib\\site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\common_app\\anaconda\\lib\\site-packages (from scikit-learn->sklearn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in d:\\common_app\\anaconda\\lib\\site-packages (from scikit-learn->sklearn) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\common_app\\anaconda\\lib\\site-packages (from scikit-learn->sklearn) (1.21.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Error parsing requirements for tensorflow-estimator: [Errno 2] No such file or directory: 'd:\\\\common_app\\\\anaconda\\\\lib\\\\site-packages\\\\tensorflow_estimator-2.3.0.dist-info\\\\METADATA'\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in d:\\common_app\\anaconda\\lib\\site-packages (4.62.2)\n",
      "Requirement already satisfied: colorama in d:\\common_app\\anaconda\\lib\\site-packages (from tqdm) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Error parsing requirements for tensorflow-estimator: [Errno 2] No such file or directory: 'd:\\\\common_app\\\\anaconda\\\\lib\\\\site-packages\\\\tensorflow_estimator-2.3.0.dist-info\\\\METADATA'\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\common_app\\anaconda\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install matplotlib\n",
    "! pip install pandas\n",
    "! pip install numpy\n",
    "! pip install sklearn\n",
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42566b2f",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c852e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d016d28",
   "metadata": {},
   "source": [
    "# 2. Recommendation system methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14750c28",
   "metadata": {},
   "source": [
    "## 2. 1 User-based collaborative filtering on MovieLens-100k dataset\n",
    "User-based collaborative filtering aims to find the similarity between users. As long as we find the preferred items of similar users, we can predict the target user's rating for the corresponding objects and find the highest-rating items, so as to recommend the selected items to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e343f1",
   "metadata": {},
   "source": [
    "### 2.1.1 Hyper-parameters setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77162eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "topK = 20# number of the top-k nearest neighbors\n",
    "testRate = 0.2# testing rate\n",
    "seed = 2# random seed\n",
    "staticDir='ml-100k' # address of data movielens-100k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e7570e",
   "metadata": {},
   "source": [
    "### 2.1.2 Data loading and training/test set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "346b6555",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_table(staticDir+'/u.user',sep=\"|\",names=['user_id','age','sex','occupation','zip_code'],encoding='latin-1',engine='python')\n",
    "ratings = pd.read_table(staticDir+'/u.data', sep='\\t', names=['user_id', 'movie_id', 'rating', 'unix_timestamp'],encoding='latin-1',engine='python')\n",
    "movies = pd.read_table(staticDir+'/u.item',engine='python', sep='|',header=None,encoding='latin-1',names=['movie_id','title','release_date','video_release_date','IMDb_URL','unknown','Action','Adventure','Animation','Children','Comedy','Crime','Documentary','Drama','Fantasy','Film-Noir','Horror','Musical','Mystery','Romance','Sci-Fi','Thriller','War','Western']) \n",
    "movies = movies.iloc[:,:5]\n",
    "#index setting\n",
    "users = users.set_index(['user_id'],drop=False)\n",
    "movies = movies.set_index(['movie_id'],drop=False)\n",
    "ratings = ratings.set_index(['user_id','movie_id'],drop=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dabeec54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>43537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  age sex  occupation zip_code\n",
       "user_id                                       \n",
       "1              1   24   M  technician    85711\n",
       "2              2   53   F       other    94043\n",
       "3              3   23   M      writer    32067\n",
       "4              4   24   M  technician    43537\n",
       "5              5   33   F       other    15213"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize user information\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47ecc571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>video_release_date</th>\n",
       "      <th>IMDb_URL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          movie_id              title release_date  video_release_date  \\\n",
       "movie_id                                                                 \n",
       "1                1   Toy Story (1995)  01-Jan-1995                 NaN   \n",
       "2                2   GoldenEye (1995)  01-Jan-1995                 NaN   \n",
       "3                3  Four Rooms (1995)  01-Jan-1995                 NaN   \n",
       "4                4  Get Shorty (1995)  01-Jan-1995                 NaN   \n",
       "5                5     Copycat (1995)  01-Jan-1995                 NaN   \n",
       "\n",
       "                                                   IMDb_URL  \n",
       "movie_id                                                     \n",
       "1         http://us.imdb.com/M/title-exact?Toy%20Story%2...  \n",
       "2         http://us.imdb.com/M/title-exact?GoldenEye%20(...  \n",
       "3         http://us.imdb.com/M/title-exact?Four%20Rooms%...  \n",
       "4         http://us.imdb.com/M/title-exact?Get%20Shorty%...  \n",
       "5         http://us.imdb.com/M/title-exact?Copycat%20(1995)  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize movie information\n",
    "movies.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af93444e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <th>242</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <th>302</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <th>377</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <th>51</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <th>346</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id  movie_id  rating  unix_timestamp\n",
       "user_id movie_id                                           \n",
       "196     242           196       242       3       881250949\n",
       "186     302           186       302       3       891717742\n",
       "22      377            22       377       1       878887116\n",
       "244     51            244        51       2       880606923\n",
       "166     346           166       346       1       886397596"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize rating information\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a861c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training/test data split\n",
    "np.random.seed(seed)\n",
    "testIndex = np.random.choice(range(ratings.shape[0]),size=int(ratings.shape[0]*testRate),replace=False)\n",
    "testRatings = ratings.iloc[testIndex,:]\n",
    "trainIndex = list(set(range(ratings.shape[0]))-set(testIndex))\n",
    "trainRatings = ratings.iloc[trainIndex,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cda7969",
   "metadata": {},
   "source": [
    "### 2.1.3 Training set process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10229651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>video_release_date</th>\n",
       "      <th>IMDb_URL</th>\n",
       "      <th>users</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>[308, 287, 148, 280, 66, 109, 181, 95, 189, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>[5, 268, 276, 87, 250, 201, 64, 13, 213, 373, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>[181, 81, 130, 49, 320, 145, 95, 99, 267, 417,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>[99, 19, 207, 295, 201, 10, 308, 328, 109, 334...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>[293, 43, 311, 109, 344, 145, 314, 308, 280, 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          movie_id              title release_date  video_release_date  \\\n",
       "movie_id                                                                 \n",
       "1                1   Toy Story (1995)  01-Jan-1995                 NaN   \n",
       "2                2   GoldenEye (1995)  01-Jan-1995                 NaN   \n",
       "3                3  Four Rooms (1995)  01-Jan-1995                 NaN   \n",
       "4                4  Get Shorty (1995)  01-Jan-1995                 NaN   \n",
       "5                5     Copycat (1995)  01-Jan-1995                 NaN   \n",
       "\n",
       "                                                   IMDb_URL  \\\n",
       "movie_id                                                      \n",
       "1         http://us.imdb.com/M/title-exact?Toy%20Story%2...   \n",
       "2         http://us.imdb.com/M/title-exact?GoldenEye%20(...   \n",
       "3         http://us.imdb.com/M/title-exact?Four%20Rooms%...   \n",
       "4         http://us.imdb.com/M/title-exact?Get%20Shorty%...   \n",
       "5         http://us.imdb.com/M/title-exact?Copycat%20(1995)   \n",
       "\n",
       "                                                      users  \n",
       "movie_id                                                     \n",
       "1         [308, 287, 148, 280, 66, 109, 181, 95, 189, 14...  \n",
       "2         [5, 268, 276, 87, 250, 201, 64, 13, 213, 373, ...  \n",
       "3         [181, 81, 130, 49, 320, 145, 95, 99, 267, 417,...  \n",
       "4         [99, 19, 207, 295, 201, 10, 308, 328, 109, 334...  \n",
       "5         [293, 43, 311, 109, 344, 145, 314, 308, 280, 4...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting the IDs of the user who watched the movies in the training set\n",
    "def calUsers(movieId):\n",
    "    try:\n",
    "        views = trainRatings.loc[(slice(None),movieId),:]\n",
    "    except:\n",
    "        return []\n",
    "    users = views['user_id'].values.tolist()\n",
    "    return users\n",
    "movies['users'] = movies['movie_id'].apply(calUsers)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60ebecc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>movies</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "      <td>[61, 189, 33, 160, 20, 202, 171, 265, 117, 47,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "      <td>[292, 251, 314, 297, 312, 281, 13, 303, 308, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "      <td>[335, 245, 337, 343, 323, 331, 294, 332, 334, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>43537</td>\n",
       "      <td>[264, 303, 361, 357, 260, 356, 294, 288, 50, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "      <td>[2, 439, 225, 110, 454, 424, 363, 98, 102, 211...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  age sex  occupation zip_code  \\\n",
       "user_id                                          \n",
       "1              1   24   M  technician    85711   \n",
       "2              2   53   F       other    94043   \n",
       "3              3   23   M      writer    32067   \n",
       "4              4   24   M  technician    43537   \n",
       "5              5   33   F       other    15213   \n",
       "\n",
       "                                                    movies  \n",
       "user_id                                                     \n",
       "1        [61, 189, 33, 160, 20, 202, 171, 265, 117, 47,...  \n",
       "2        [292, 251, 314, 297, 312, 281, 13, 303, 308, 2...  \n",
       "3        [335, 245, 337, 343, 323, 331, 294, 332, 334, ...  \n",
       "4        [264, 303, 361, 357, 260, 356, 294, 288, 50, 2...  \n",
       "5        [2, 439, 225, 110, 454, 424, 363, 98, 102, 211...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting the movie ids watched by users in all training sets \n",
    "def calMovies(userId):\n",
    "    try:\n",
    "        views = trainRatings.loc[(userId,slice(None)),:]\n",
    "    except:\n",
    "        return []\n",
    "    movies = views['movie_id'].values.tolist()\n",
    "    return movies\n",
    "users['movies'] = users['user_id'].apply(calMovies)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfda7f33",
   "metadata": {},
   "source": [
    "### 2.1.4 Similarity measure\n",
    "The similarity between $\\text {user}_u$ and $\\text {user}_v$ is defined as follows:\n",
    "\\begin{equation}\n",
    "Sim_{u,v}=\\frac{|\\text { items}_{\\text {user}_u} \\cap \\text {items}_{\\text {user}_v}|}{\\sqrt{|\\text {items}_{\\text {user}_u} |\\times |\\text {items}_{\\text {user}_v}|}}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\text{items}_{\\text {user}_u}$ represents the movies watched by $\\text {user}_u$. Generally speaking, the denominator represents the square root of multiplication between the cardinality of watching recording of $\\text {user}_u$ and $\\text {user}_v$. Similarly, the numerator is the cardinality of the intersection of $\\text {user}_u$ and $\\text {user}_v$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00651910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>user_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.116008</td>\n",
       "      <td>0.069067</td>\n",
       "      <td>0.064449</td>\n",
       "      <td>0.275500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.116008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142887</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.036380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.069067</td>\n",
       "      <td>0.142887</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.238145</td>\n",
       "      <td>0.012377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064449</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.238145</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.275500</td>\n",
       "      <td>0.036380</td>\n",
       "      <td>0.012377</td>\n",
       "      <td>0.040423</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "user_id         1         2         3         4         5\n",
       "user_id                                                  \n",
       "1        1.000000  0.116008  0.069067  0.064449  0.275500\n",
       "2        0.116008  1.000000  0.142887  0.133333  0.036380\n",
       "3        0.069067  0.142887  1.000000  0.238145  0.012377\n",
       "4        0.064449  0.133333  0.238145  1.000000  0.040423\n",
       "5        0.275500  0.036380  0.012377  0.040423  1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = pd.DataFrame(0,columns=users.index,index=users.index)\n",
    "def calSim(userId1,userId2):\n",
    "    user1Items = users.loc[userId1,'movies']\n",
    "    user2Items = users.loc[userId2,'movies']\n",
    "    cross = list(set(user1Items) & set(user2Items))\n",
    "    sim = len(cross)/((max(1e-1,len(user1Items))*max(1e-1,len(user2Items)))**0.5)\n",
    "    return sim \n",
    "def fillSims(row):\n",
    "    userIds = pd.Series(row.index)\n",
    "    row[:] = userIds.apply(calSim,args=(row.name,))\n",
    "    return row\n",
    "sims = sims.apply(fillSims,axis=1)\n",
    "sims.iloc[:5,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2db7f4e",
   "metadata": {},
   "source": [
    "### 2.1.5 Calculating the top-k nearest neighbors of $\\text {user}_u$\n",
    "Based on the similarity matrix, we select top-k nearest neighbors of every user and present them in a new colunm named \"near\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf0b1b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>movies</th>\n",
       "      <th>near</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "      <td>[61, 189, 33, 160, 20, 202, 171, 265, 117, 47,...</td>\n",
       "      <td>[457, 435, 916, 648, 933, 276, 864, 297, 805, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "      <td>[292, 251, 314, 297, 312, 281, 13, 303, 308, 2...</td>\n",
       "      <td>[701, 673, 926, 131, 306, 569, 937, 520, 486, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "      <td>[335, 245, 337, 343, 323, 331, 294, 332, 334, ...</td>\n",
       "      <td>[752, 489, 784, 587, 863, 529, 783, 428, 126, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>43537</td>\n",
       "      <td>[264, 303, 361, 357, 260, 356, 294, 288, 50, 2...</td>\n",
       "      <td>[33, 816, 750, 408, 443, 783, 725, 596, 355, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "      <td>[2, 439, 225, 110, 454, 424, 363, 98, 102, 211...</td>\n",
       "      <td>[222, 648, 407, 56, 495, 254, 497, 457, 727, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  age sex  occupation zip_code  \\\n",
       "user_id                                          \n",
       "1              1   24   M  technician    85711   \n",
       "2              2   53   F       other    94043   \n",
       "3              3   23   M      writer    32067   \n",
       "4              4   24   M  technician    43537   \n",
       "5              5   33   F       other    15213   \n",
       "\n",
       "                                                    movies  \\\n",
       "user_id                                                      \n",
       "1        [61, 189, 33, 160, 20, 202, 171, 265, 117, 47,...   \n",
       "2        [292, 251, 314, 297, 312, 281, 13, 303, 308, 2...   \n",
       "3        [335, 245, 337, 343, 323, 331, 294, 332, 334, ...   \n",
       "4        [264, 303, 361, 357, 260, 356, 294, 288, 50, 2...   \n",
       "5        [2, 439, 225, 110, 454, 424, 363, 98, 102, 211...   \n",
       "\n",
       "                                                      near  \n",
       "user_id                                                     \n",
       "1        [457, 435, 916, 648, 933, 276, 864, 297, 805, ...  \n",
       "2        [701, 673, 926, 131, 306, 569, 937, 520, 486, ...  \n",
       "3        [752, 489, 784, 587, 863, 529, 783, 428, 126, ...  \n",
       "4        [33, 816, 750, 408, 443, 783, 725, 596, 355, 6...  \n",
       "5        [222, 648, 407, 56, 495, 254, 497, 457, 727, 1...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calNearUsers(userId):\n",
    "    nearUserIds = sims.loc[:,userId].sort_values(ascending=False)[1:topK+1]\n",
    "    nearUserIds = nearUserIds.index.tolist()\n",
    "    return nearUserIds\n",
    "users['near'] = users['user_id'].apply(calNearUsers)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2be21ab",
   "metadata": {},
   "source": [
    "### 2.1.6 Prediction and evaluation\n",
    "Predicting the scores of $\\text {user}_0$ on item $\\text{t}_1$ with the following equation.\n",
    "\\begin{equation}\n",
    "P_{\\mathrm{u} 0, t 1}=\\frac{\\sum_{\\mathrm{ui} \\in A_{u 0}} \\operatorname{sim}(u i, u 0) \\times\\left(R_{u i, t 1}\\right)}{\\sum_{u i \\in A_{u 0}}|\\operatorname{sim}(u i, u 0)|}\n",
    "\\end{equation}\n",
    "where $A_{u 0}$ denotes the set of neighbors of $\\text {user}_0$. $\\operatorname{sim}(u i, u 0)$ represents the similarity score between the user $\\text {user}_i$ and user $\\text {user}_0$. $R_{u i, t 1}$ is the rate score of neighbor user $ui$ on item $t1$.\n",
    "As such, we can predict the rate of any users on every item. The performance is evaluated via the mean absulate error on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a5ee63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE of test set is 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaohu4\\AppData\\Local\\Temp/ipykernel_8736/3504372224.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testRatings['predict'] = testRatings.apply(predict,axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <th>273</th>\n",
       "      <td>157</td>\n",
       "      <td>273</td>\n",
       "      <td>5</td>\n",
       "      <td>886889876</td>\n",
       "      <td>3.740361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <th>1065</th>\n",
       "      <td>405</td>\n",
       "      <td>1065</td>\n",
       "      <td>1</td>\n",
       "      <td>885546069</td>\n",
       "      <td>3.790151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <th>550</th>\n",
       "      <td>244</td>\n",
       "      <td>550</td>\n",
       "      <td>1</td>\n",
       "      <td>880602264</td>\n",
       "      <td>3.164083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <th>768</th>\n",
       "      <td>378</td>\n",
       "      <td>768</td>\n",
       "      <td>4</td>\n",
       "      <td>880333598</td>\n",
       "      <td>2.786181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <th>111</th>\n",
       "      <td>919</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>875288681</td>\n",
       "      <td>3.691650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id  movie_id  rating  unix_timestamp   predict\n",
       "user_id movie_id                                                     \n",
       "157     273           157       273       5       886889876  3.740361\n",
       "405     1065          405      1065       1       885546069  3.790151\n",
       "244     550           244       550       1       880602264  3.164083\n",
       "378     768           378       768       4       880333598  2.786181\n",
       "919     111           919       111       4       875288681  3.691650"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(row):\n",
    "    userId = row['user_id']\n",
    "    movieId = row['movie_id']\n",
    "    #select top-K nearest neighbors\n",
    "    nearUserIds = users.loc[userId,'near']\n",
    "    #index the movie_id of user in the training set\n",
    "    itemUserIds = movies.loc[movieId,'users']\n",
    "    #calculate the user intersection of the same item\n",
    "    cross = list(set(nearUserIds) & set(itemUserIds))   \n",
    "    #predict the scores\n",
    "    up = 0\n",
    "    down = 0\n",
    "    for nearUserId in cross:\n",
    "        sim = sims.loc[nearUserId,userId]\n",
    "        down += sim\n",
    "        #Scores from neighboring users\n",
    "        score = trainRatings.loc[(nearUserId,movieId),'rating']\n",
    "        up += score * sim\n",
    "    if up == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return up/down\n",
    "    \n",
    "#Testing\n",
    "testRatings['predict'] = testRatings.apply(predict,axis=1)\n",
    "testRatings = testRatings.dropna()\n",
    "mae = MAE(testRatings['rating'],testRatings['predict'])\n",
    "print('The MAE of test set is %.2f'%mae)\n",
    "testRatings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc200f1",
   "metadata": {},
   "source": [
    "## 2. 2 Matrix factorization on MovieLens-1m dataset for top-k recommendation\n",
    "Matrix factorization factorizes the user-item rating matrix to fill in the missing rate values. \n",
    "Given $n$ users and $m$ items, the user-item rating matrix is represented as $R_{n\\times m}$, and the mathematic concept of matrix factorization can be formulated as \n",
    "\\begin{equation}\n",
    "\\mathbf{R}_{n\\times m} \\approx \\mathbf{P}_{n\\times k} \\times \\mathbf{Q}_{k\\times m}=\\hat{\\mathbf{R}}_{n\\times m}.\n",
    "\\end{equation}\n",
    "where $k$ is the dimension of hidden features. Matrix $P$ represents the association between a user and the hidden features while matrix $Q$ represents the association between an item and the hidden features. We can get the prediction of a rating of an item by the calculation of the dot product of the $i$-th user and j-th item as follows:\n",
    "\\begin{equation}\n",
    "\\hat{r}_{i j}=p_i^T q_j=\\sum_{k=1}^k p_{i k} q_{k j}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14161a34",
   "metadata": {},
   "source": [
    "We utilize the square error to measure the difference between $\\mathbf{R}_{n\\times m}$ and $\\hat{\\mathbf{R}}_{n\\times m}$ as:\n",
    "\\begin{equation}\n",
    "e_{i j}^2=\\left(r_{i j}-\\hat{r}_{i j}\\right)^2=\\left(r_{i j}-\\sum_{k=1}^K p_{i k} q_{k j}\\right)^2.\n",
    "\\end{equation}\n",
    "\n",
    "and use gradient descent to minimize the error. The updates of each entry of $\\mathbf{P}$ and $\\mathbf{Q}$ can be presented as:\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "&p_{i k}^{\\prime}=p_{i k}+\\alpha \\frac{\\partial}{\\partial p_{i k}} e_{i j}^2=p_{i k}+2 \\alpha e_{i j} q_{k j}, \\\\\n",
    "&q_{k j}^{\\prime}=q_{k j}+\\alpha \\frac{\\partial}{\\partial q_{k j}} e_{i j}^2=q_{k j}+2 \\alpha e_{i j} p_{i k}.\n",
    "\\end{aligned}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7a5be5",
   "metadata": {},
   "source": [
    "### 2.2.1 Data loading and U-I rating matrix building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e451e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 3186, 4, 978300019),\n",
       " (1, 1270, 5, 978300055),\n",
       " (1, 1721, 4, 978300055),\n",
       " (1, 1022, 5, 978300055),\n",
       " (1, 2340, 3, 978300103),\n",
       " (1, 1836, 5, 978300172),\n",
       " (1, 3408, 4, 978300275),\n",
       " (1, 2804, 5, 978300719),\n",
       " (1, 1207, 4, 978300719),\n",
       " (1, 1193, 5, 978300760),\n",
       " (1, 720, 3, 978300760),\n",
       " (1, 260, 4, 978300760),\n",
       " (1, 919, 4, 978301368),\n",
       " (1, 608, 4, 978301398),\n",
       " (1, 2692, 4, 978301570),\n",
       " (1, 1961, 5, 978301590),\n",
       " (1, 2028, 5, 978301619),\n",
       " (1, 3105, 5, 978301713),\n",
       " (1, 938, 4, 978301752),\n",
       " (1, 1035, 5, 978301753),\n",
       " (1, 1962, 4, 978301753),\n",
       " (1, 2018, 4, 978301777),\n",
       " (1, 150, 5, 978301777),\n",
       " (1, 1028, 5, 978301777),\n",
       " (1, 1097, 4, 978301953),\n",
       " (1, 914, 3, 978301968),\n",
       " (1, 1287, 5, 978302039),\n",
       " (1, 2797, 4, 978302039),\n",
       " (1, 2762, 4, 978302091),\n",
       " (1, 1246, 4, 978302091),\n",
       " (1, 661, 3, 978302109),\n",
       " (1, 2918, 4, 978302124),\n",
       " (1, 531, 4, 978302149),\n",
       " (1, 3114, 4, 978302174),\n",
       " (1, 2791, 4, 978302188),\n",
       " (1, 2321, 3, 978302205),\n",
       " (1, 1029, 5, 978302205),\n",
       " (1, 1197, 3, 978302268),\n",
       " (1, 594, 4, 978302268),\n",
       " (1, 2398, 4, 978302281),\n",
       " (1, 1545, 4, 978824139),\n",
       " (1, 527, 5, 978824195),\n",
       " (1, 595, 5, 978824268),\n",
       " (1, 2687, 3, 978824268),\n",
       " (1, 745, 3, 978824268),\n",
       " (1, 588, 4, 978824268),\n",
       " (1, 1, 5, 978824268),\n",
       " (1, 2355, 5, 978824291),\n",
       " (1, 2294, 4, 978824291),\n",
       " (1, 783, 4, 978824291),\n",
       " (1, 1566, 4, 978824330),\n",
       " (1, 1907, 4, 978824330),\n",
       " (1, 48, 5, 978824351),\n",
       " (2, 1198, 4, 978298124),\n",
       " (2, 1210, 4, 978298151),\n",
       " (2, 1217, 3, 978298151),\n",
       " (2, 2717, 3, 978298196),\n",
       " (2, 1293, 5, 978298261),\n",
       " (2, 2943, 4, 978298372),\n",
       " (2, 1225, 5, 978298391),\n",
       " (2, 1193, 5, 978298413),\n",
       " (2, 318, 5, 978298413),\n",
       " (2, 3030, 4, 978298434),\n",
       " (2, 2858, 4, 978298434),\n",
       " (2, 1213, 2, 978298458),\n",
       " (2, 1945, 5, 978298458),\n",
       " (2, 1207, 4, 978298478),\n",
       " (2, 593, 5, 978298517),\n",
       " (2, 3095, 4, 978298517),\n",
       " (2, 3468, 5, 978298542),\n",
       " (2, 1873, 4, 978298542),\n",
       " (2, 515, 5, 978298542),\n",
       " (2, 1090, 2, 978298580),\n",
       " (2, 2501, 5, 978298600),\n",
       " (2, 3035, 4, 978298625),\n",
       " (2, 110, 5, 978298625),\n",
       " (2, 2067, 5, 978298625),\n",
       " (2, 3147, 5, 978298652),\n",
       " (2, 1247, 5, 978298652),\n",
       " (2, 3105, 4, 978298673),\n",
       " (2, 1357, 5, 978298709),\n",
       " (2, 1196, 5, 978298730),\n",
       " (2, 1957, 5, 978298750),\n",
       " (2, 1953, 4, 978298775),\n",
       " (2, 920, 5, 978298775),\n",
       " (2, 1834, 4, 978298813),\n",
       " (2, 1084, 3, 978298813),\n",
       " (2, 1962, 5, 978298813),\n",
       " (2, 3471, 5, 978298814),\n",
       " (2, 3654, 3, 978298814),\n",
       " (2, 3735, 3, 978298814),\n",
       " (2, 1259, 5, 978298841),\n",
       " (2, 1954, 5, 978298841),\n",
       " (2, 1784, 5, 978298841),\n",
       " (2, 2728, 3, 978298881),\n",
       " (2, 1968, 2, 978298881),\n",
       " (2, 1103, 3, 978298905),\n",
       " (2, 902, 2, 978298905),\n",
       " (2, 3451, 4, 978298924),\n",
       " (2, 3578, 5, 978298958),\n",
       " (2, 2852, 3, 978298958),\n",
       " (2, 3334, 4, 978298958),\n",
       " (2, 3068, 4, 978299000),\n",
       " (2, 265, 4, 978299026),\n",
       " (2, 2312, 3, 978299046),\n",
       " (2, 590, 5, 978299083),\n",
       " (2, 1253, 3, 978299120),\n",
       " (2, 3071, 4, 978299120),\n",
       " (2, 1244, 3, 978299143),\n",
       " (2, 3699, 2, 978299173),\n",
       " (2, 1955, 4, 978299200),\n",
       " (2, 1245, 2, 978299200),\n",
       " (2, 2236, 5, 978299220),\n",
       " (2, 3678, 3, 978299250),\n",
       " (2, 982, 4, 978299269),\n",
       " (2, 2194, 4, 978299297),\n",
       " (2, 2268, 5, 978299297),\n",
       " (2, 1442, 4, 978299297),\n",
       " (2, 3255, 4, 978299321),\n",
       " (2, 647, 3, 978299351),\n",
       " (2, 235, 3, 978299351),\n",
       " (2, 1096, 4, 978299386),\n",
       " (2, 1124, 5, 978299418),\n",
       " (2, 498, 3, 978299418),\n",
       " (2, 1246, 5, 978299418),\n",
       " (2, 3893, 1, 978299535),\n",
       " (2, 1537, 4, 978299620),\n",
       " (2, 1188, 4, 978299620),\n",
       " (2, 2396, 4, 978299641),\n",
       " (2, 2359, 3, 978299666),\n",
       " (2, 2321, 3, 978299666),\n",
       " (2, 356, 5, 978299686),\n",
       " (2, 3108, 3, 978299712),\n",
       " (2, 1265, 3, 978299712),\n",
       " (2, 3809, 3, 978299712),\n",
       " (2, 589, 4, 978299773),\n",
       " (2, 2028, 4, 978299773),\n",
       " (2, 2571, 4, 978299773),\n",
       " (2, 457, 4, 978299773),\n",
       " (2, 2916, 3, 978299809),\n",
       " (2, 1610, 5, 978299809),\n",
       " (2, 480, 5, 978299809),\n",
       " (2, 163, 4, 978299809),\n",
       " (2, 380, 5, 978299809),\n",
       " (2, 3418, 4, 978299809),\n",
       " (2, 3256, 2, 978299839),\n",
       " (2, 1408, 3, 978299839),\n",
       " (2, 21, 1, 978299839),\n",
       " (2, 349, 4, 978299839),\n",
       " (2, 1527, 4, 978299839),\n",
       " (2, 2353, 4, 978299861),\n",
       " (2, 2006, 3, 978299861),\n",
       " (2, 2278, 3, 978299889),\n",
       " (2, 1370, 5, 978299889),\n",
       " (2, 648, 4, 978299913),\n",
       " (2, 2427, 2, 978299913),\n",
       " (2, 1792, 3, 978299941),\n",
       " (2, 1372, 3, 978299941),\n",
       " (2, 1552, 3, 978299941),\n",
       " (2, 2490, 3, 978299966),\n",
       " (2, 1385, 3, 978299966),\n",
       " (2, 780, 3, 978299966),\n",
       " (2, 2881, 3, 978300002),\n",
       " (2, 3107, 2, 978300002),\n",
       " (2, 368, 4, 978300002),\n",
       " (2, 1801, 3, 978300002),\n",
       " (2, 165, 3, 978300002),\n",
       " (2, 459, 3, 978300002),\n",
       " (2, 442, 3, 978300025),\n",
       " (2, 1597, 3, 978300025),\n",
       " (2, 2628, 3, 978300051),\n",
       " (2, 1690, 3, 978300051),\n",
       " (2, 3257, 3, 978300073),\n",
       " (2, 736, 4, 978300100),\n",
       " (2, 2002, 5, 978300100),\n",
       " (2, 2126, 3, 978300123),\n",
       " (2, 292, 3, 978300123),\n",
       " (2, 95, 2, 978300143),\n",
       " (2, 1687, 3, 978300174),\n",
       " (2, 434, 2, 978300174),\n",
       " (2, 1544, 4, 978300174),\n",
       " (2, 1917, 3, 978300174),\n",
       " (3, 593, 3, 978297018),\n",
       " (3, 2858, 4, 978297039),\n",
       " (3, 3534, 3, 978297068),\n",
       " (3, 1968, 4, 978297068),\n",
       " (3, 1431, 3, 978297095),\n",
       " (3, 1961, 4, 978297095),\n",
       " (3, 1266, 5, 978297396),\n",
       " (3, 1378, 5, 978297419),\n",
       " (3, 1379, 4, 978297419),\n",
       " (3, 3671, 5, 978297419),\n",
       " (3, 590, 4, 978297439),\n",
       " (3, 260, 5, 978297512),\n",
       " (3, 1196, 4, 978297539),\n",
       " (3, 2871, 4, 978297539),\n",
       " (3, 1197, 5, 978297570),\n",
       " (3, 1198, 5, 978297570),\n",
       " (3, 3168, 4, 978297570),\n",
       " (3, 1210, 4, 978297600),\n",
       " (3, 1291, 4, 978297600),\n",
       " (3, 2167, 5, 978297600),\n",
       " (3, 1580, 3, 978297663),\n",
       " (3, 1261, 1, 978297663),\n",
       " (3, 480, 4, 978297690),\n",
       " (3, 1615, 5, 978297710),\n",
       " (3, 653, 4, 978297757),\n",
       " (3, 733, 5, 978297757),\n",
       " (3, 2006, 4, 978297757),\n",
       " (3, 2470, 4, 978297777),\n",
       " (3, 2115, 4, 978297777),\n",
       " (3, 1049, 4, 978297805),\n",
       " (3, 552, 4, 978297837),\n",
       " (3, 2617, 2, 978297837),\n",
       " (3, 648, 3, 978297867),\n",
       " (3, 2735, 4, 978297867),\n",
       " (3, 1136, 5, 978298079),\n",
       " (3, 3114, 3, 978298103),\n",
       " (3, 3421, 4, 978298147),\n",
       " (3, 1394, 4, 978298147),\n",
       " (3, 2997, 3, 978298147),\n",
       " (3, 1304, 5, 978298166),\n",
       " (3, 3619, 2, 978298201),\n",
       " (3, 1270, 3, 978298231),\n",
       " (3, 1079, 5, 978298296),\n",
       " (3, 1259, 5, 978298296),\n",
       " (3, 1265, 2, 978298316),\n",
       " (3, 1641, 2, 978298430),\n",
       " (3, 2355, 5, 978298430),\n",
       " (3, 3552, 5, 978298459),\n",
       " (3, 104, 4, 978298486),\n",
       " (3, 3868, 3, 978298486),\n",
       " (3, 2081, 4, 978298504),\n",
       " (4, 1210, 3, 978293924),\n",
       " (4, 1097, 4, 978293964),\n",
       " (4, 3468, 5, 978294008),\n",
       " (4, 480, 4, 978294008),\n",
       " (4, 3527, 1, 978294008),\n",
       " (4, 260, 5, 978294199),\n",
       " (4, 1196, 2, 978294199),\n",
       " (4, 1198, 5, 978294199),\n",
       " (4, 1387, 5, 978294199),\n",
       " (4, 2028, 5, 978294230),\n",
       " (4, 2366, 4, 978294230),\n",
       " (4, 1201, 5, 978294230),\n",
       " (4, 2692, 5, 978294230),\n",
       " (4, 2947, 5, 978294230),\n",
       " (4, 1214, 4, 978294260),\n",
       " (4, 3418, 4, 978294260),\n",
       " (4, 3702, 4, 978294260),\n",
       " (4, 1240, 5, 978294260),\n",
       " (4, 2951, 4, 978294282),\n",
       " (4, 1036, 4, 978294282),\n",
       " (4, 1954, 5, 978294282),\n",
       " (5, 2717, 1, 978241072),\n",
       " (5, 908, 4, 978241072),\n",
       " (5, 919, 4, 978241072),\n",
       " (5, 1250, 5, 978241112),\n",
       " (5, 356, 1, 978241112),\n",
       " (5, 2858, 4, 978241390),\n",
       " (5, 1127, 1, 978241390),\n",
       " (5, 2188, 1, 978241390),\n",
       " (5, 2683, 3, 978241434),\n",
       " (5, 3051, 2, 978241434),\n",
       " (5, 2997, 5, 978241556),\n",
       " (5, 2770, 4, 978241981),\n",
       " (5, 2355, 5, 978241981),\n",
       " (5, 2908, 4, 978241981),\n",
       " (5, 3786, 3, 978241981),\n",
       " (5, 3016, 4, 978242016),\n",
       " (5, 2759, 3, 978242080),\n",
       " (5, 1093, 2, 978242080),\n",
       " (5, 2599, 5, 978242323),\n",
       " (5, 3113, 1, 978242323),\n",
       " (5, 3408, 3, 978242323),\n",
       " (5, 2428, 3, 978242541),\n",
       " (5, 2959, 4, 978242541),\n",
       " (5, 3409, 3, 978242541),\n",
       " (5, 2333, 4, 978242607),\n",
       " (5, 2716, 3, 978242607),\n",
       " (5, 2580, 4, 978242607),\n",
       " (5, 2607, 2, 978242607),\n",
       " (5, 2318, 4, 978242640),\n",
       " (5, 2390, 4, 978242679),\n",
       " (5, 913, 5, 978242740),\n",
       " (5, 2723, 4, 978242788),\n",
       " (5, 2734, 2, 978242788),\n",
       " (5, 968, 3, 978242847),\n",
       " (5, 299, 3, 978242934),\n",
       " (5, 2013, 3, 978242934),\n",
       " (5, 24, 1, 978242934),\n",
       " (5, 2560, 4, 978242977),\n",
       " (5, 1513, 4, 978242977),\n",
       " (5, 2692, 4, 978242977),\n",
       " (5, 3081, 3, 978243054),\n",
       " (5, 2395, 5, 978243054),\n",
       " (5, 2762, 3, 978243054),\n",
       " (5, 2700, 4, 978243085),\n",
       " (5, 3176, 2, 978243085),\n",
       " (5, 2806, 2, 978243085),\n",
       " (5, 2337, 5, 978243121),\n",
       " (5, 2070, 2, 978243121),\n",
       " (5, 2721, 3, 978243121),\n",
       " (5, 2987, 4, 978243170),\n",
       " (5, 3793, 2, 978243170),\n",
       " (5, 3578, 2, 978243803),\n",
       " (5, 3624, 3, 978243803),\n",
       " (5, 3514, 2, 978243869),\n",
       " (5, 3513, 1, 978243896),\n",
       " (5, 3744, 1, 978243896),\n",
       " (5, 3799, 3, 978243937),\n",
       " (5, 501, 1, 978244001),\n",
       " (5, 1243, 3, 978244001),\n",
       " (5, 1617, 3, 978244025),\n",
       " (5, 2028, 2, 978244053),\n",
       " (5, 1046, 5, 978244114),\n",
       " (5, 3083, 5, 978244114),\n",
       " (5, 296, 4, 978244177),\n",
       " (5, 593, 4, 978244177),\n",
       " (5, 318, 3, 978244177),\n",
       " (5, 608, 4, 978244177),\n",
       " (5, 1213, 5, 978244177),\n",
       " (5, 50, 5, 978244205),\n",
       " (5, 1719, 3, 978244205),\n",
       " (5, 1089, 5, 978244205),\n",
       " (5, 860, 2, 978244493),\n",
       " (5, 1192, 5, 978244493),\n",
       " (5, 2571, 5, 978244493),\n",
       " (5, 896, 4, 978244493),\n",
       " (5, 714, 4, 978244493),\n",
       " (5, 1704, 3, 978244517),\n",
       " (5, 1684, 3, 978244540),\n",
       " (5, 800, 2, 978244540),\n",
       " (5, 1554, 3, 978244540),\n",
       " (5, 994, 5, 978244540),\n",
       " (5, 3728, 2, 978244568),\n",
       " (5, 2289, 4, 978244568),\n",
       " (5, 176, 4, 978244568),\n",
       " (5, 1788, 3, 978244603),\n",
       " (5, 1730, 4, 978244603),\n",
       " (5, 562, 4, 978244603),\n",
       " (5, 34, 4, 978244603),\n",
       " (5, 1912, 3, 978244624),\n",
       " (5, 162, 4, 978244624),\n",
       " (5, 2282, 3, 978244667),\n",
       " (5, 1649, 4, 978244667),\n",
       " (5, 41, 4, 978244692),\n",
       " (5, 1175, 5, 978244759),\n",
       " (5, 728, 4, 978244759),\n",
       " (5, 2437, 2, 978244759),\n",
       " (5, 581, 3, 978244808),\n",
       " (5, 2291, 5, 978244808),\n",
       " (5, 2159, 1, 978244808),\n",
       " (5, 36, 3, 978244808),\n",
       " (5, 1449, 4, 978244830),\n",
       " (5, 3163, 5, 978244852),\n",
       " (5, 1171, 4, 978244852),\n",
       " (5, 461, 3, 978244893),\n",
       " (5, 3267, 4, 978244893),\n",
       " (5, 1509, 3, 978244962),\n",
       " (5, 3046, 3, 978244962),\n",
       " (5, 3418, 3, 978244962),\n",
       " (5, 32, 4, 978244962),\n",
       " (5, 39, 3, 978245037),\n",
       " (5, 265, 3, 978245037),\n",
       " (5, 1529, 4, 978245037),\n",
       " (5, 3260, 4, 978245065),\n",
       " (5, 29, 5, 978245065),\n",
       " (5, 1095, 4, 978245065),\n",
       " (5, 3499, 3, 978245065),\n",
       " (5, 1635, 4, 978245314),\n",
       " (5, 1279, 1, 978245314),\n",
       " (5, 1923, 3, 978245314),\n",
       " (5, 1500, 3, 978245314),\n",
       " (5, 1650, 3, 978245314),\n",
       " (5, 866, 4, 978245334),\n",
       " (5, 47, 3, 978245334),\n",
       " (5, 1734, 4, 978245334),\n",
       " (5, 215, 3, 978245422),\n",
       " (5, 3006, 3, 978245422),\n",
       " (5, 2890, 4, 978245445),\n",
       " (5, 2323, 4, 978245445),\n",
       " (5, 272, 3, 978245487),\n",
       " (5, 1535, 4, 978245513),\n",
       " (5, 1759, 4, 978245513),\n",
       " (5, 1594, 1, 978245548),\n",
       " (5, 2359, 3, 978245568),\n",
       " (5, 1517, 4, 978245568),\n",
       " (5, 1885, 4, 978245568),\n",
       " (5, 1392, 4, 978245645),\n",
       " (5, 2916, 1, 978245645),\n",
       " (5, 1610, 4, 978245645),\n",
       " (5, 3100, 1, 978245645),\n",
       " (5, 16, 3, 978245645),\n",
       " (5, 1747, 2, 978245663),\n",
       " (5, 497, 3, 978245687),\n",
       " (5, 1466, 3, 978245695),\n",
       " (5, 2384, 3, 978245708),\n",
       " (5, 2058, 1, 978245740),\n",
       " (5, 1732, 5, 978245740),\n",
       " (5, 150, 2, 978245763),\n",
       " (5, 733, 1, 978245763),\n",
       " (5, 1721, 1, 978245763),\n",
       " (5, 1729, 4, 978245763),\n",
       " (5, 2353, 3, 978245790),\n",
       " (5, 2952, 2, 978245790),\n",
       " (5, 509, 4, 978245829),\n",
       " (5, 224, 3, 978245829),\n",
       " (5, 1429, 3, 978245829),\n",
       " (5, 357, 2, 978245829),\n",
       " (5, 321, 3, 978245863),\n",
       " (5, 348, 4, 978245863),\n",
       " (5, 515, 4, 978245891),\n",
       " (5, 1715, 4, 978245891),\n",
       " (5, 1653, 2, 978245891),\n",
       " (5, 412, 2, 978245891),\n",
       " (5, 6, 2, 978245916),\n",
       " (5, 3020, 1, 978245916),\n",
       " (5, 1643, 3, 978245916),\n",
       " (5, 3249, 1, 978245916),\n",
       " (5, 3476, 3, 978245916),\n",
       " (5, 1966, 2, 978245931),\n",
       " (5, 1268, 2, 978245948),\n",
       " (5, 3386, 2, 978245948),\n",
       " (5, 1794, 3, 978245966),\n",
       " (5, 506, 4, 978245999),\n",
       " (5, 377, 4, 978245999),\n",
       " (5, 1580, 4, 978245999),\n",
       " (5, 2268, 2, 978246033),\n",
       " (5, 202, 2, 978246033),\n",
       " (5, 1683, 3, 978246108),\n",
       " (5, 1722, 2, 978246108),\n",
       " (5, 194, 3, 978246108),\n",
       " (5, 3079, 2, 978246162),\n",
       " (5, 1921, 4, 978246162),\n",
       " (5, 2725, 2, 978246162),\n",
       " (5, 3266, 2, 978246162),\n",
       " (5, 1191, 2, 978246426),\n",
       " (5, 1897, 4, 978246426),\n",
       " (5, 2427, 5, 978246450),\n",
       " (5, 1733, 3, 978246450),\n",
       " (5, 1909, 3, 978246479),\n",
       " (5, 52, 2, 978246479),\n",
       " (5, 1527, 3, 978246479),\n",
       " (5, 551, 4, 978246504),\n",
       " (5, 353, 2, 978246504),\n",
       " (5, 229, 3, 978246528),\n",
       " (5, 2029, 4, 978246555),\n",
       " (5, 1485, 3, 978246576),\n",
       " (5, 3105, 2, 978246576),\n",
       " (5, 1884, 3, 978246576),\n",
       " (5, 288, 2, 978246585),\n",
       " (6, 3072, 4, 978236075),\n",
       " (6, 2006, 4, 978236122),\n",
       " (6, 912, 4, 978236122),\n",
       " (6, 1043, 4, 978236219),\n",
       " (6, 3534, 4, 978236219),\n",
       " (6, 1210, 3, 978236219),\n",
       " (6, 377, 3, 978236383),\n",
       " (6, 17, 4, 978236383),\n",
       " (6, 1441, 4, 978236383),\n",
       " (6, 3685, 3, 978236519),\n",
       " (6, 1296, 3, 978236519),\n",
       " (6, 2081, 4, 978236567),\n",
       " (6, 3699, 4, 978236567),\n",
       " (6, 2100, 3, 978236567),\n",
       " (6, 1674, 4, 978236567),\n",
       " (6, 2802, 4, 978236612),\n",
       " (6, 1959, 3, 978236612),\n",
       " (6, 2406, 5, 978236670),\n",
       " (6, 1101, 4, 978236670),\n",
       " (6, 3501, 5, 978236670),\n",
       " (6, 1088, 5, 978236670),\n",
       " (6, 2469, 3, 978236670),\n",
       " (6, 3524, 3, 978236719),\n",
       " (6, 1188, 4, 978236771),\n",
       " (6, 2858, 1, 978236809),\n",
       " (6, 2396, 4, 978236809),\n",
       " (6, 1806, 3, 978236876),\n",
       " (6, 569, 4, 978236876),\n",
       " (6, 2506, 3, 978236975),\n",
       " (6, 2082, 3, 978236975),\n",
       " (6, 1, 4, 978237008),\n",
       " (6, 2321, 3, 978237034),\n",
       " (6, 590, 3, 978237232),\n",
       " (6, 2966, 5, 978237273),\n",
       " (6, 296, 2, 978237379),\n",
       " (6, 838, 4, 978237444),\n",
       " (6, 34, 4, 978237444),\n",
       " (6, 588, 4, 978237511),\n",
       " (6, 595, 4, 978237511),\n",
       " (6, 1688, 5, 978237570),\n",
       " (6, 364, 4, 978237570),\n",
       " (6, 48, 5, 978237570),\n",
       " (6, 1566, 4, 978237570),\n",
       " (6, 199, 5, 978237570),\n",
       " (6, 1030, 4, 978237691),\n",
       " (6, 1380, 5, 978237691),\n",
       " (6, 1035, 5, 978237767),\n",
       " (6, 3604, 5, 978237767),\n",
       " (6, 1947, 5, 978237767),\n",
       " (6, 914, 5, 978237767),\n",
       " (6, 1028, 4, 978237767),\n",
       " (6, 3600, 3, 978237813),\n",
       " (6, 2017, 3, 978237813),\n",
       " (6, 3610, 3, 978237813),\n",
       " (6, 368, 4, 978237909),\n",
       " (6, 383, 4, 978237909),\n",
       " (6, 266, 4, 978237909),\n",
       " (6, 3074, 5, 978238036),\n",
       " (6, 3508, 3, 978238036),\n",
       " (6, 3682, 3, 978238036),\n",
       " (6, 1007, 3, 978238036),\n",
       " (6, 3578, 4, 978238195),\n",
       " (6, 3753, 5, 978238195),\n",
       " (6, 3536, 5, 978238230),\n",
       " (6, 3408, 5, 978238230),\n",
       " (6, 3624, 4, 978238256),\n",
       " (6, 3565, 4, 978238288),\n",
       " (6, 3717, 4, 978238371),\n",
       " (6, 920, 4, 978238851),\n",
       " (6, 1569, 4, 978238948),\n",
       " (6, 597, 5, 978239019),\n",
       " (7, 1270, 4, 978234581),\n",
       " (7, 480, 4, 978234607),\n",
       " (7, 442, 4, 978234632),\n",
       " (7, 1196, 5, 978234632),\n",
       " (7, 1221, 4, 978234659),\n",
       " (7, 648, 4, 978234737),\n",
       " (7, 3578, 3, 978234737),\n",
       " (7, 3793, 3, 978234737),\n",
       " (7, 1997, 5, 978234737),\n",
       " (7, 3753, 4, 978234737),\n",
       " (7, 1610, 5, 978234786),\n",
       " (7, 589, 5, 978234786),\n",
       " (7, 2571, 5, 978234786),\n",
       " (7, 457, 5, 978234786),\n",
       " (7, 110, 5, 978234786),\n",
       " (7, 2028, 5, 978234786),\n",
       " (7, 377, 3, 978234810),\n",
       " (7, 3418, 3, 978234810),\n",
       " (7, 2916, 5, 978234842),\n",
       " (7, 6, 4, 978234842),\n",
       " (7, 733, 5, 978234842),\n",
       " (7, 474, 5, 978234842),\n",
       " (7, 1580, 4, 978234842),\n",
       " (7, 861, 4, 978234874),\n",
       " (7, 2353, 5, 978234874),\n",
       " (7, 380, 5, 978234874),\n",
       " (7, 1573, 4, 978234874),\n",
       " (7, 1722, 4, 978234874),\n",
       " (7, 3256, 5, 978234874),\n",
       " (7, 349, 5, 978234874),\n",
       " (7, 3107, 3, 978234898),\n",
       " (8, 1210, 4, 978228789),\n",
       " (8, 111, 5, 978228832),\n",
       " (8, 908, 5, 978228882),\n",
       " (8, 3481, 4, 978228882),\n",
       " (8, 1573, 4, 978228960),\n",
       " (8, 480, 5, 978228960),\n",
       " (8, 589, 5, 978229138),\n",
       " (8, 393, 2, 978229138),\n",
       " (8, 2028, 5, 978229138),\n",
       " (8, 3265, 5, 978229138),\n",
       " (8, 3418, 3, 978229138),\n",
       " (8, 2692, 5, 978229138),\n",
       " (8, 2916, 5, 978229172),\n",
       " (8, 2571, 5, 978229172),\n",
       " (8, 110, 5, 978229172),\n",
       " (8, 377, 4, 978229204),\n",
       " (8, 2427, 5, 978229204),\n",
       " (8, 555, 4, 978229204),\n",
       " (8, 3267, 5, 978229204),\n",
       " (8, 163, 5, 978229246),\n",
       " (8, 3107, 5, 978229246),\n",
       " (8, 2278, 3, 978229293),\n",
       " (8, 2490, 2, 978229293),\n",
       " (8, 1916, 5, 978229293),\n",
       " (8, 1580, 4, 978229293),\n",
       " (8, 733, 3, 978229347),\n",
       " (8, 2006, 3, 978229347),\n",
       " (8, 3256, 5, 978229347),\n",
       " (8, 349, 4, 978229347),\n",
       " (8, 2699, 5, 978229347),\n",
       " (8, 288, 5, 978229391),\n",
       " (8, 2600, 2, 978229391),\n",
       " (8, 25, 5, 978229477),\n",
       " (8, 1265, 5, 978229524),\n",
       " (8, 2396, 5, 978229524),\n",
       " (8, 39, 3, 978229571),\n",
       " (8, 265, 4, 978229571),\n",
       " (8, 17, 4, 978229571),\n",
       " (8, 1059, 3, 978229614),\n",
       " (8, 1277, 3, 978229614),\n",
       " (8, 1735, 4, 978229614),\n",
       " (8, 1393, 5, 978229702),\n",
       " (8, 2291, 5, 978229702),\n",
       " (8, 1639, 5, 978229702),\n",
       " (8, 2858, 5, 978229817),\n",
       " (8, 1213, 5, 978229817),\n",
       " (8, 296, 5, 978229857),\n",
       " (8, 527, 4, 978229857),\n",
       " (8, 608, 5, 978229857),\n",
       " (8, 1704, 5, 978229900),\n",
       " (8, 2329, 5, 978229900),\n",
       " (8, 3260, 3, 978229957),\n",
       " (8, 3386, 3, 978229979),\n",
       " (8, 3252, 3, 978230013),\n",
       " (8, 1730, 4, 978230013),\n",
       " (8, 36, 4, 978230013),\n",
       " (8, 1466, 4, 978230052),\n",
       " (8, 2908, 3, 978230052),\n",
       " (8, 16, 4, 978230095),\n",
       " (8, 2336, 3, 978230120),\n",
       " (8, 2686, 4, 978230152),\n",
       " (8, 3250, 3, 978230184),\n",
       " (8, 562, 5, 978230184),\n",
       " (8, 3006, 3, 978230227),\n",
       " (8, 3148, 3, 978230248),\n",
       " (8, 337, 5, 978230248),\n",
       " (8, 58, 5, 978230286),\n",
       " (8, 73, 4, 978230286),\n",
       " (8, 1673, 5, 978230356),\n",
       " (8, 1120, 4, 978230391),\n",
       " (8, 1411, 5, 978230391),\n",
       " (8, 538, 3, 978230391),\n",
       " (8, 3246, 4, 978230391),\n",
       " (8, 508, 3, 978230435),\n",
       " (8, 161, 3, 978230435),\n",
       " (8, 506, 3, 978230483),\n",
       " (8, 2324, 3, 978230483),\n",
       " (8, 3147, 5, 978230550),\n",
       " (8, 2442, 4, 978230550),\n",
       " (8, 1840, 4, 978230577),\n",
       " (8, 150, 4, 978230611),\n",
       " (8, 524, 5, 978230611),\n",
       " (8, 1660, 3, 978230611),\n",
       " (8, 1678, 5, 978230649),\n",
       " (8, 3105, 4, 978230666),\n",
       " (8, 476, 3, 978230687),\n",
       " (8, 14, 4, 978230756),\n",
       " (8, 1357, 4, 978230800),\n",
       " (8, 1721, 5, 978230800),\n",
       " (8, 2268, 3, 978230852),\n",
       " (8, 1682, 4, 978230852),\n",
       " (8, 3186, 4, 978230852),\n",
       " (8, 2712, 3, 978230886),\n",
       " (8, 1653, 5, 978230886),\n",
       " (8, 650, 5, 978230943),\n",
       " (8, 2702, 3, 978230943),\n",
       " (8, 253, 5, 978230943),\n",
       " (8, 1589, 4, 978230943),\n",
       " (8, 345, 3, 978230943),\n",
       " (8, 1621, 3, 978230966),\n",
       " (8, 24, 4, 978230966),\n",
       " (8, 1810, 2, 978231031),\n",
       " (8, 2541, 3, 978231031),\n",
       " (8, 1693, 3, 978231121),\n",
       " (8, 269, 4, 978231121),\n",
       " (8, 151, 4, 978231150),\n",
       " (8, 454, 3, 978231173),\n",
       " (8, 465, 5, 978231173),\n",
       " (8, 2297, 3, 978231252),\n",
       " (8, 2688, 3, 978231429),\n",
       " (8, 1476, 3, 978231493),\n",
       " (8, 3259, 4, 978231571),\n",
       " (8, 1836, 4, 978231592),\n",
       " (8, 266, 4, 978231614),\n",
       " (8, 230, 4, 978231637),\n",
       " (8, 1701, 4, 978231659),\n",
       " (8, 3528, 4, 978231687),\n",
       " (8, 2023, 3, 978231802),\n",
       " (8, 2320, 2, 978231802),\n",
       " (8, 282, 3, 978231802),\n",
       " (8, 2429, 2, 978231890),\n",
       " (8, 1711, 3, 978231890),\n",
       " (8, 3425, 3, 978231982),\n",
       " (8, 1488, 3, 978231982),\n",
       " (8, 3173, 2, 978232012),\n",
       " (8, 510, 3, 978232056),\n",
       " (8, 105, 4, 978232056),\n",
       " (8, 2314, 3, 978232056),\n",
       " (8, 1801, 3, 978232056),\n",
       " (8, 4, 3, 978232203),\n",
       " (8, 1027, 4, 978232203),\n",
       " (8, 3155, 3, 978232231),\n",
       " (8, 42, 3, 978232754),\n",
       " (8, 3500, 3, 978232754),\n",
       " (8, 3213, 3, 978233462),\n",
       " (8, 1274, 5, 978233462),\n",
       " (8, 1, 4, 978233496),\n",
       " (8, 741, 5, 978233526),\n",
       " (8, 3257, 3, 978247143),\n",
       " (9, 3751, 4, 978224859),\n",
       " (9, 1961, 5, 978224859),\n",
       " (9, 912, 4, 978224879),\n",
       " (9, 1210, 4, 978224893),\n",
       " (9, 3178, 3, 978224908),\n",
       " (9, 1221, 4, 978224908),\n",
       " (9, 3916, 3, 978225153),\n",
       " (9, 3948, 3, 978225177),\n",
       " (9, 527, 5, 978225303),\n",
       " (9, 1233, 3, 978225303),\n",
       " (9, 593, 5, 978225314),\n",
       " (9, 1213, 4, 978225314),\n",
       " (9, 2858, 4, 978225333),\n",
       " (9, 50, 4, 978225333),\n",
       " (9, 1148, 4, 978225333),\n",
       " (9, 920, 3, 978225401),\n",
       " (9, 1307, 4, 978225429),\n",
       " (9, 2692, 4, 978225429),\n",
       " (9, 1552, 2, 978225489),\n",
       " (9, 3510, 3, 978225570),\n",
       " (9, 3408, 4, 978225570),\n",
       " (9, 3793, 4, 978225581),\n",
       " (9, 3755, 2, 978225613),\n",
       " (9, 3623, 4, 978225671),\n",
       " (9, 3298, 4, 978225686),\n",
       " (9, 3717, 3, 978225709),\n",
       " (9, 3301, 2, 978225718),\n",
       " (9, 3513, 3, 978225730),\n",
       " (9, 3452, 2, 978225746),\n",
       " (9, 3826, 2, 978225758),\n",
       " (9, 3484, 2, 978225778),\n",
       " (9, 3148, 3, 978225827),\n",
       " (9, 318, 5, 978225883),\n",
       " (9, 720, 4, 978225898),\n",
       " (9, 745, 4, 978225898),\n",
       " (9, 608, 4, 978225898),\n",
       " (9, 2028, 5, 978225908),\n",
       " (9, 1617, 4, 978225924),\n",
       " (9, 1704, 4, 978225924),\n",
       " (9, 1, 5, 978225952),\n",
       " (9, 2599, 2, 978225952),\n",
       " (9, 3114, 4, 978225952),\n",
       " (9, 1223, 4, 978225968),\n",
       " (9, 1089, 4, 978225968),\n",
       " (9, 2571, 5, 978225984),\n",
       " (9, 3160, 3, 978225984),\n",
       " (9, 2762, 4, 978225984),\n",
       " (9, 457, 5, 978226006),\n",
       " (9, 1310, 3, 978226006),\n",
       " (9, 162, 4, 978226023),\n",
       " (9, 150, 3, 978226041),\n",
       " (9, 3006, 3, 978226041),\n",
       " (9, 25, 4, 978226041),\n",
       " (9, 2355, 4, 978226054),\n",
       " (9, 1265, 4, 978226066),\n",
       " (9, 2324, 5, 978226066),\n",
       " (9, 1393, 3, 978226081),\n",
       " (9, 3147, 4, 978226081),\n",
       " (9, 47, 5, 978226093),\n",
       " (9, 1639, 4, 978226109),\n",
       " (9, 1784, 3, 978226109),\n",
       " (9, 1500, 4, 978226123),\n",
       " (9, 2959, 4, 978226123),\n",
       " (9, 377, 3, 978226150),\n",
       " (9, 1446, 3, 978226150),\n",
       " (9, 1669, 3, 978226150),\n",
       " (9, 223, 4, 978226165),\n",
       " (9, 1923, 5, 978226165),\n",
       " (9, 3253, 4, 978226165),\n",
       " (9, 2166, 4, 978226197),\n",
       " (9, 1358, 4, 978226207),\n",
       " (9, 3255, 4, 978226216),\n",
       " (9, 1584, 5, 978226233),\n",
       " (9, 1466, 4, 978226248),\n",
       " (9, 1721, 5, 978226248),\n",
       " (9, 778, 5, 978226248),\n",
       " (9, 1343, 3, 978226261),\n",
       " (9, 1060, 4, 978226261),\n",
       " (9, 412, 3, 978226261),\n",
       " (9, 300, 4, 978226277),\n",
       " (9, 1777, 4, 978226291),\n",
       " (9, 2890, 5, 978226291),\n",
       " (9, 1682, 4, 978226302),\n",
       " (9, 508, 3, 978226315),\n",
       " (9, 994, 4, 978226328),\n",
       " (9, 1912, 3, 978226343),\n",
       " (9, 1921, 4, 978226368),\n",
       " (9, 590, 5, 978226434),\n",
       " (9, 480, 4, 978226448),\n",
       " (9, 3270, 3, 978226448),\n",
       " (9, 2302, 4, 978226463),\n",
       " (9, 597, 3, 978226473),\n",
       " (9, 2268, 4, 978226495),\n",
       " (9, 838, 3, 978226495),\n",
       " (9, 805, 3, 978226564),\n",
       " (9, 529, 5, 978226564),\n",
       " (9, 349, 4, 978226564),\n",
       " (9, 428, 3, 978226580),\n",
       " (9, 524, 4, 978226599),\n",
       " (9, 16, 4, 978226599),\n",
       " (9, 1653, 4, 978226619),\n",
       " (9, 1356, 3, 978226644),\n",
       " (9, 861, 2, 978226665),\n",
       " (9, 2278, 4, 978226665),\n",
       " (9, 367, 3, 978226678),\n",
       " (9, 2294, 4, 978226678),\n",
       " (10, 597, 4, 978224375),\n",
       " (10, 743, 3, 978224375),\n",
       " (10, 858, 3, 978224375),\n",
       " (10, 1948, 4, 978224400),\n",
       " (10, 1210, 4, 978224400),\n",
       " (10, 1282, 5, 978224549),\n",
       " (10, 2312, 5, 978224549),\n",
       " (10, 3751, 5, 978224549),\n",
       " (10, 551, 3, 978224549),\n",
       " (10, 2858, 3, 978224627),\n",
       " (10, 2033, 3, 978224675),\n",
       " (10, 3155, 5, 978224705),\n",
       " (10, 2791, 4, 978224705),\n",
       " (10, 480, 4, 978224705),\n",
       " (10, 1544, 4, 978224749),\n",
       " (10, 2135, 4, 978224779),\n",
       " (10, 2657, 4, 978224779),\n",
       " (10, 3675, 5, 978224779),\n",
       " (10, 2399, 4, 978224821),\n",
       " (10, 648, 4, 978224925),\n",
       " (10, 3189, 4, 978225033),\n",
       " (10, 3481, 4, 978225050),\n",
       " (10, 3408, 4, 978225070),\n",
       " (10, 3629, 3, 978225428),\n",
       " (10, 1204, 4, 978225456),\n",
       " (10, 2762, 5, 978225541),\n",
       " (10, 1148, 5, 978225541),\n",
       " (10, 919, 5, 978225561),\n",
       " (10, 1927, 3, 978225599),\n",
       " (10, 1198, 5, 978225630),\n",
       " (10, 541, 5, 978225630),\n",
       " (10, 1234, 4, 978225630),\n",
       " (10, 2300, 5, 978225682),\n",
       " (10, 3037, 5, 978225682),\n",
       " (10, 1293, 4, 978225682),\n",
       " (10, 912, 3, 978225708),\n",
       " (10, 1270, 4, 978225735),\n",
       " (10, 1291, 5, 978225735),\n",
       " (10, 1954, 3, 978225735),\n",
       " (10, 3114, 4, 978225759),\n",
       " (10, 1302, 5, 978225779),\n",
       " (10, 1214, 4, 978225800),\n",
       " (10, 1079, 5, 978225800),\n",
       " (10, 1215, 4, 978225824),\n",
       " (10, 1080, 5, 978225824),\n",
       " (10, 1201, 2, 978225853),\n",
       " (10, 110, 4, 978225853),\n",
       " (10, 588, 4, 978225900),\n",
       " (10, 223, 2, 978225900),\n",
       " (10, 913, 3, 978225900),\n",
       " (10, 1278, 5, 978225922),\n",
       " (10, 2918, 5, 978225922),\n",
       " (10, 954, 5, 978225922),\n",
       " (10, 2716, 4, 978225952),\n",
       " (10, 1294, 4, 978225952),\n",
       " (10, 1387, 3, 978225952),\n",
       " (10, 3868, 3, 978225997),\n",
       " (10, 3035, 3, 978225997),\n",
       " (10, 2997, 4, 978226026),\n",
       " (10, 1028, 5, 978226068),\n",
       " (10, 3296, 4, 978226103),\n",
       " (10, 3702, 3, 978226103),\n",
       " (10, 589, 4, 978226128),\n",
       " (10, 277, 3, 978226147),\n",
       " (10, 2336, 5, 978226165),\n",
       " (10, 2959, 3, 978226165),\n",
       " (10, 2872, 4, 978226186),\n",
       " (10, 926, 4, 978226212),\n",
       " (10, 3095, 4, 978226212),\n",
       " (10, 3198, 3, 978226212),\n",
       " (10, 3471, 5, 978226231),\n",
       " (10, 1254, 3, 978226254),\n",
       " (10, 1411, 4, 978226287),\n",
       " (10, 2324, 5, 978226287),\n",
       " (10, 3671, 4, 978226287),\n",
       " (10, 1682, 5, 978226319),\n",
       " (10, 150, 5, 978226319),\n",
       " (10, 2000, 5, 978226319),\n",
       " (10, 1271, 5, 978226349),\n",
       " (10, 3194, 4, 978226349),\n",
       " (10, 3358, 5, 978226378),\n",
       " (10, 1580, 5, 978226401),\n",
       " (10, 2501, 5, 978226402),\n",
       " (10, 802, 5, 978226425),\n",
       " (10, 2863, 4, 978226443),\n",
       " (10, 1, 5, 978226474),\n",
       " (10, 953, 5, 978226474),\n",
       " (10, 1269, 5, 978226500),\n",
       " (10, 3525, 2, 978226500),\n",
       " (10, 2355, 4, 978226500),\n",
       " (10, 3087, 5, 978226500),\n",
       " (10, 1307, 5, 978226546),\n",
       " (10, 1250, 3, 978226572),\n",
       " (10, 364, 4, 978226698),\n",
       " (10, 1084, 4, 978226698),\n",
       " (10, 3451, 5, 978226739),\n",
       " (10, 2100, 5, 978226739),\n",
       " (10, 180, 2, 978226766),\n",
       " (10, 1947, 5, 978226805),\n",
       " (10, 914, 5, 978226805),\n",
       " (10, 3703, 2, 978226805),\n",
       " (10, 356, 5, 978226833),\n",
       " (10, 1253, 5, 978226866),\n",
       " (10, 2080, 4, 978226866),\n",
       " (10, 3066, 2, 978226866),\n",
       " (10, 2529, 4, 978226866),\n",
       " (10, 3699, 5, 978226866),\n",
       " (10, 3723, 4, 978226896),\n",
       " (10, 2291, 4, 978226896),\n",
       " (10, 594, 5, 978226913),\n",
       " (10, 3097, 5, 978226951),\n",
       " (10, 1230, 4, 978226968),\n",
       " (10, 2804, 5, 978227003),\n",
       " (10, 368, 4, 978227003),\n",
       " (10, 2040, 4, 978227003),\n",
       " (10, 587, 5, 978227028),\n",
       " (10, 920, 5, 978227029),\n",
       " (10, 653, 4, 978227051),\n",
       " (10, 62, 5, 978227051),\n",
       " (10, 2496, 4, 978227087),\n",
       " (10, 3100, 3, 978227105),\n",
       " (10, 3359, 3, 978227125),\n",
       " (10, 3255, 4, 978227143),\n",
       " (10, 943, 4, 978227166),\n",
       " (10, 2948, 4, 978227166),\n",
       " (10, 1408, 4, 978227188),\n",
       " (10, 2874, 5, 978227188),\n",
       " (10, 915, 5, 978227215),\n",
       " (10, 918, 5, 978227215),\n",
       " (10, 539, 5, 978227239),\n",
       " (10, 1653, 5, 978227239),\n",
       " (10, 592, 4, 978227263),\n",
       " (10, 1104, 4, 978227263),\n",
       " (10, 1257, 5, 978227300),\n",
       " (10, 1088, 5, 978227300),\n",
       " (10, 2041, 3, 978227300),\n",
       " (10, 1243, 5, 978227300),\n",
       " (10, 2302, 5, 978227317),\n",
       " (10, 2321, 4, 978227336),\n",
       " (10, 3386, 4, 978227379),\n",
       " (10, 1287, 3, 978227425),\n",
       " (10, 1967, 5, 978227442),\n",
       " (10, 1012, 3, 978227462),\n",
       " (10, 3247, 4, 978227481),\n",
       " (10, 1921, 4, 978227503),\n",
       " (10, 316, 5, 978227503),\n",
       " (10, 2662, 4, 978227529),\n",
       " (10, 104, 3, 978227551),\n",
       " (10, 971, 5, 978227551),\n",
       " (10, 3086, 4, 978227574),\n",
       " (10, 1357, 5, 978227625),\n",
       " (10, 2294, 4, 978227625),\n",
       " (10, 2371, 4, 978227625),\n",
       " (10, 590, 5, 978227646),\n",
       " (10, 2078, 4, 978227646),\n",
       " (10, 2174, 5, 978227669),\n",
       " (10, 963, 5, 978227669),\n",
       " (10, 2001, 4, 978227669),\n",
       " (10, 3363, 5, 978227696),\n",
       " (10, 2617, 4, 978227696),\n",
       " (10, 7, 4, 978227763),\n",
       " (10, 1019, 4, 978227763),\n",
       " (10, 2003, 4, 978227807),\n",
       " (10, 2137, 4, 978227842),\n",
       " (10, 2967, 4, 978227848),\n",
       " (10, 1356, 5, 978227871),\n",
       " (10, 3701, 3, 978227871),\n",
       " (10, 1220, 4, 978227912),\n",
       " (10, 2115, 5, 978227934),\n",
       " (10, 1517, 3, 978227961),\n",
       " (10, 2018, 4, 978227993),\n",
       " (10, 2081, 5, 978228053),\n",
       " (10, 3039, 4, 978228053),\n",
       " (10, 1025, 4, 978228074),\n",
       " (10, 2393, 4, 978228074),\n",
       " (10, 2011, 4, 978228118),\n",
       " (10, 2470, 5, 978228118),\n",
       " (10, 3500, 5, 978228153),\n",
       " (10, 1101, 4, 978228153),\n",
       " (10, 596, 4, 978228174),\n",
       " (10, 2012, 5, 978228174),\n",
       " (10, 2622, 5, 978228212),\n",
       " (10, 2161, 5, 978228212),\n",
       " (10, 1375, 4, 978228212),\n",
       " (10, 1923, 5, 978228288),\n",
       " (10, 1372, 4, 978228288),\n",
       " (10, 2746, 5, 978228307),\n",
       " (10, 3928, 4, 978228307),\n",
       " (10, 3704, 2, 978228364),\n",
       " (10, 3174, 4, 978228364),\n",
       " (10, 2628, 3, 978228408),\n",
       " (10, 671, 3, 978228408),\n",
       " (10, 1032, 4, 978228428),\n",
       " (10, 1441, 5, 978228451),\n",
       " (10, 3809, 5, 978228451),\n",
       " (10, 3591, 5, 978228525),\n",
       " (10, 1031, 4, 978228546),\n",
       " (10, 2045, 3, 978228575),\n",
       " (10, 3608, 3, 978228601),\n",
       " (10, 1042, 5, 978228601),\n",
       " (10, 2015, 5, 978228601),\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_item_list = []\n",
    "split=\"::\"\n",
    "for data_item in open('ml-1m/ratings.dat'):\n",
    "    # data_item_list：[(6040, 858, 4, 956703932), (1, 593, 3, 1112484661), ...]\n",
    "    temp_tuple = list(data_item.strip().split(split)[:4])  # delimiter\n",
    "    temp_tuple[0] = int(temp_tuple[0])  # user ID\n",
    "    temp_tuple[1] = int(temp_tuple[1])  # item ID\n",
    "    temp_tuple[2] = int(temp_tuple[2])  # item rating，\n",
    "    temp_tuple[3] = int(temp_tuple[3])  # timestamp\n",
    "    data_item_list.append(tuple(temp_tuple))\n",
    "# We order data_item_list based on the timestamp and the user ID\n",
    "data_item_list = sorted(data_item_list, key=lambda tup: tup[3])\n",
    "data_item_list = sorted(data_item_list, key=lambda tup: tup[0])\n",
    "data_item_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a45cab",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def getUIMat(data):\n",
    "    # build U-I rating matrix\n",
    "    user_list = [i[0] for i in data]\n",
    "    item_list = [i[1] for i in data]\n",
    "    UI_matrix = np.zeros((max(user_list) + 1, max(item_list) + 1))\n",
    "    for each_interaction in tqdm(data, total=len(data)):\n",
    "        UI_matrix[each_interaction[0]][each_interaction[1]] = each_interaction[2]\n",
    "    return UI_matrix\n",
    "R = getUIMat(data_item_list)\n",
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cb576f",
   "metadata": {},
   "source": [
    "### 2.2.2 Matrix factorization model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66a11a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF():\n",
    "    def __init__(self, R, K, alpha, beta, iterations):\n",
    "        \"\"\"\n",
    "        parameters\n",
    "        - R (ndarray)   : user-item rating matrix\n",
    "        - K (int)       : dimension of hidden features\n",
    "        - alpha (float) : learning rate\n",
    "        - beta (float)  : regularization parameter\n",
    "        - beta (int)    : number of iterations\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        self.R = R\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def train(self):\n",
    "        # Initialize the hidden user-feature matrix and item-feature matrix\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        # Building training samples\n",
    "        self.samples = [\n",
    "            (i, j, self.R[i, j])\n",
    "            for i in range(self.num_users)\n",
    "            for j in range(self.num_items)\n",
    "            if self.R[i, j] > 0\n",
    "        ]\n",
    "\n",
    "        # Iterate the gradient descent to update matrices\n",
    "        training_process = []\n",
    "        for i in tqdm(range(self.iterations), total=self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            mse = self.mse()\n",
    "            training_process.append((i, mse))\n",
    "            if (i == 0) or ((i+1) % (self.iterations / 10) == 0):\n",
    "                print(\"Iteration: %d ; error = %.4f\" % (i+1, mse))\n",
    "\n",
    "        return training_process\n",
    "    \n",
    "    def mse(self):\n",
    "        \"\"\"\n",
    "        Mean square error\n",
    "        \"\"\"\n",
    "        xs, ys = self.R.nonzero()\n",
    "        predicted = self.full_matrix()\n",
    "        error = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            error += pow(self.R[x, y] - predicted[x, y], 2)\n",
    "        return np.sqrt(error)/len(self.R)\n",
    "\n",
    "    def sgd(self):\n",
    "        \"\"\"\n",
    "        Stochastic gradient descent\n",
    "        \"\"\"\n",
    "        for i, j, r in self.samples:\n",
    "            # calculate the prediction and error\n",
    "            prediction = self.get_rating(i, j)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            # update user and item hidden feature matrices\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "\n",
    "    def get_rating(self, i, j):\n",
    "        \"\"\"\n",
    "        Get preficted score (r_ij)，where i is the user id and j denotes item id\n",
    "        \"\"\"\n",
    "        prediction =  self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "\n",
    "    def full_matrix(self):\n",
    "        \"\"\"\n",
    "        Obtain the fully prediction matrix\n",
    "        \"\"\"\n",
    "        return  self.P.dot(self.Q.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3555d9",
   "metadata": {},
   "source": [
    "### 2.2.3 Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a28eb1c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [00:11<00:45, 11.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 ; error = 0.1807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:22<00:34, 11.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2 ; error = 0.1633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:34<00:22, 11.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3 ; error = 0.1604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:45<00:11, 11.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4 ; error = 0.1599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:56<00:00, 11.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5 ; error = 0.1597\n",
      "------ user ------\n",
      "1\n",
      "------ temp_topN ------\n",
      "[922, 750, 3030, 1193, 1148, 2905, 745, 912, 2019, 318]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Train the MF model\n",
    "mf = MF(R, K=20, alpha=0.01, beta=0.3, iterations=5)\n",
    "mf.train()\n",
    "\n",
    "# ------ Recommendation example ------ #\n",
    "# Recommend top-10 items to user_1\n",
    "each_user = 1\n",
    "user_ratings = mf.full_matrix()[each_user].tolist()\n",
    "# print(user_ratings)\n",
    "topN = [(i, user_ratings.index(i)) for i in user_ratings] # Correlate the item id with corresponding scores\n",
    "topN = [i[1] for i in sorted(topN, key=lambda x:x[0], reverse=True)][:10] # select top-10 items\n",
    "\n",
    "print(\"------ user ------\")\n",
    "print(each_user)\n",
    "print(\"------ temp_topN ------\")\n",
    "print(topN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fcf9dd",
   "metadata": {},
   "source": [
    "# 3. Practice--Linear regression for recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d89b77",
   "metadata": {},
   "source": [
    "Linear regression is also a popular method to fill up the missing rates. Traditionally, for linear regression, the formula is usually written as:\n",
    "\\begin{equation}\n",
    "h=\\theta_0+\\theta_1 X\n",
    "\\end{equation}\n",
    "Here, $h$ is the hypothesis or the predicted value, $X$ is the input feature, and $\\theta_0$ and $\\theta_1$ are the coefficients.\n",
    "\n",
    "In this recommendation system, we will use the other ratings of the same movie as the input X and predict the missing values. We will avoid the bias term $\\theta_0$. We define the total loss function which will indicate the distance between the predicted ratings and the original ratings as follows:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "&J\\left(x^1, \\ldots, x^{n_m}, \\theta^1, \\ldots, \\theta^{n_u}\\right) \\\\\n",
    "&\\quad=\\frac{1}{2} \\sum_{(i, j): r(i, j)=1}\\left(\\left(\\theta^j\\right)^T x^i-y^{i, j}\\right)^2+\\frac{\\lambda}{2} \\sum_{i=1}^{n_m} \\sum_{k=1}^n\\left(x_k^i\\right)^2+\\frac{\\lambda}{2} \\sum_{j=1}^{n_u} \\sum_{k=1}^n\\left(\\theta_k^j\\right)^2\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "where $r(i, j)$ indicate whether user $j$ has rated movie $i$, $y^{i, j}$ is the rate score given by user $j$ to movie $i$. \n",
    "The first term of this formula shows the squared of the error term. We take the square to avoid any negative values. Use 1/2 to optimize the squared and we calculate the error term where r(i, j) = 1. The second and third term of the equation above is the regularization term. The first regularization is used for finding features X that belongs to same movie category and the second one is is useful to regularize any overfitting or underfitting problem.\n",
    "\n",
    "After we getting the loss function, the gradient descent updates the theta in each iteration. Here is the formula for gradient descent:\n",
    "\\begin{equation}\n",
    "\\theta_k^j=\\theta_k^j-\\alpha\\left(\\sum_{i: r(i, j)=1}\\left(\\left(\\theta^j\\right)^T x^i-y^{i, j}\\right) x_k^i+\\lambda \\theta_k^j\\right)\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "x_k^i=x_k^i-\\alpha\\left(\\sum_{j: r(i, j)=1}\\left(\\left(\\theta^j\\right)^T x^i-y^{i, j}\\right) \\theta_k^j+\\lambda x_k^i\\right)\n",
    "\\end{equation}\n",
    "where $\\alpha$ is the learning rate. In each iteration, $\\theta$ and $X$ will be updated and eventually becomes stable.\n",
    "\n",
    "In this practice, you need to write codes to implement the linear regression on a new dataset from Andrew Ngs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a217e98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96731972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>933</th>\n",
       "      <th>934</th>\n",
       "      <th>935</th>\n",
       "      <th>936</th>\n",
       "      <th>937</th>\n",
       "      <th>938</th>\n",
       "      <th>939</th>\n",
       "      <th>940</th>\n",
       "      <th>941</th>\n",
       "      <th>942</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 943 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  933  934  935  936  \\\n",
       "0    5    4    0    0    4    4    0    0    0    4  ...    2    3    4    0   \n",
       "1    3    0    0    0    3    0    0    0    0    0  ...    4    0    0    0   \n",
       "2    4    0    0    0    0    0    0    0    0    0  ...    0    0    4    0   \n",
       "3    3    0    0    0    0    0    5    0    0    4  ...    5    0    0    0   \n",
       "4    3    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "\n",
       "   937  938  939  940  941  942  \n",
       "0    4    0    0    5    0    0  \n",
       "1    0    0    0    0    0    5  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    2    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 943 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading movie rate\n",
    "y = pd.read_excel('ex8_movies.xlsx', sheet_name = 'y', header=None)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c32c501d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1682, 943)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# That means we have 1682 movies and 943 users.\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "187cb3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>933</th>\n",
       "      <th>934</th>\n",
       "      <th>935</th>\n",
       "      <th>936</th>\n",
       "      <th>937</th>\n",
       "      <th>938</th>\n",
       "      <th>939</th>\n",
       "      <th>940</th>\n",
       "      <th>941</th>\n",
       "      <th>942</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 943 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0      1      2      3      4      5      6      7      8      9    ...  \\\n",
       "0  True   True  False  False   True   True  False  False  False   True  ...   \n",
       "1  True  False  False  False   True  False  False  False  False  False  ...   \n",
       "2  True  False  False  False  False  False  False  False  False  False  ...   \n",
       "3  True  False  False  False  False  False   True  False  False   True  ...   \n",
       "4  True  False  False  False  False  False  False  False  False  False  ...   \n",
       "\n",
       "     933    934    935    936    937    938    939    940    941    942  \n",
       "0   True   True   True  False   True  False  False   True  False  False  \n",
       "1   True  False  False  False  False  False  False  False  False   True  \n",
       "2  False  False   True  False  False  False  False  False  False  False  \n",
       "3   True  False  False  False  False  False   True  False  False  False  \n",
       "4  False  False  False  False  False  False  False  False  False  False  \n",
       "\n",
       "[5 rows x 943 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This dataset contains true if the user provided a rating and False if the user did not provide the rating.\n",
    "r = pd.read_excel('ex8_movies.xlsx', sheet_name='R', header=None)\n",
    "r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1593736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to convert these boolean values into numeric values. I will replace True with 1 and False with 0.\n",
    "for i in range(len(r.columns)):\n",
    "    r[i] = r[i].replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4a3aea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.048686</td>\n",
       "      <td>-0.400232</td>\n",
       "      <td>1.194119</td>\n",
       "      <td>0.371128</td>\n",
       "      <td>0.407607</td>\n",
       "      <td>0.974407</td>\n",
       "      <td>-0.058410</td>\n",
       "      <td>0.861721</td>\n",
       "      <td>-0.697290</td>\n",
       "      <td>0.288746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.780851</td>\n",
       "      <td>-0.385626</td>\n",
       "      <td>0.521198</td>\n",
       "      <td>0.227355</td>\n",
       "      <td>0.570109</td>\n",
       "      <td>0.641264</td>\n",
       "      <td>-0.550006</td>\n",
       "      <td>0.704021</td>\n",
       "      <td>-0.485835</td>\n",
       "      <td>-0.564624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.641509</td>\n",
       "      <td>-0.547854</td>\n",
       "      <td>-0.083796</td>\n",
       "      <td>-0.598519</td>\n",
       "      <td>-0.017694</td>\n",
       "      <td>0.299736</td>\n",
       "      <td>-0.720807</td>\n",
       "      <td>0.838546</td>\n",
       "      <td>-0.694832</td>\n",
       "      <td>-1.134796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.453618</td>\n",
       "      <td>-0.800218</td>\n",
       "      <td>0.680481</td>\n",
       "      <td>-0.081743</td>\n",
       "      <td>0.136601</td>\n",
       "      <td>0.907561</td>\n",
       "      <td>0.277682</td>\n",
       "      <td>0.369300</td>\n",
       "      <td>-1.261208</td>\n",
       "      <td>-0.235581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.937538</td>\n",
       "      <td>0.106090</td>\n",
       "      <td>0.361953</td>\n",
       "      <td>0.086646</td>\n",
       "      <td>0.287505</td>\n",
       "      <td>0.518644</td>\n",
       "      <td>-0.056871</td>\n",
       "      <td>0.914573</td>\n",
       "      <td>-0.819334</td>\n",
       "      <td>-0.542847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.048686 -0.400232  1.194119  0.371128  0.407607  0.974407 -0.058410   \n",
       "1  0.780851 -0.385626  0.521198  0.227355  0.570109  0.641264 -0.550006   \n",
       "2  0.641509 -0.547854 -0.083796 -0.598519 -0.017694  0.299736 -0.720807   \n",
       "3  0.453618 -0.800218  0.680481 -0.081743  0.136601  0.907561  0.277682   \n",
       "4  0.937538  0.106090  0.361953  0.086646  0.287505  0.518644 -0.056871   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.861721 -0.697290  0.288746  \n",
       "1  0.704021 -0.485835 -0.564624  \n",
       "2  0.838546 -0.694832 -1.134796  \n",
       "3  0.369300 -1.261208 -0.235581  \n",
       "4  0.914573 -0.819334 -0.542847  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have features X in this dataset:\n",
    "X = pd.read_excel('movie_params.xlsx', sheet_name='X', header=None)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c14561e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1682, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have 10 features of each movie.\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "703eb638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def costfunction(X, y, r, theta, Lambda):\n",
    "    \"\"\"\n",
    "    Please code below\n",
    "    Input parameters\n",
    "        - X: movie feature\n",
    "        - y: rate values\n",
    "        - r: rate index\n",
    "        - theta: theta value in linear regression\n",
    "        - Lambda: hyper-parameter to regulate the effects of regularization\n",
    "    Outputs:\n",
    "        - J: mean square error between predicted and real rates\n",
    "        - grad: total loss\n",
    "    \"\"\"\n",
    "    predictions = \n",
    "    err = predictions-y\n",
    "    J = \n",
    "    reg_x = \n",
    "    reg_theta = \n",
    "    grad = J + reg_x + reg_theta\n",
    "    return J, grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce6354ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X, y, r, theta, Lambda, num_iter, alpha):\n",
    "    \"\"\"\n",
    "    Please code below\n",
    "    Input parameters\n",
    "        - X: movie feature\n",
    "        - y: rate values\n",
    "        - r: rate index\n",
    "        - theta: theta value in linear regression\n",
    "        - Lambda: hyper-parameter to regulate the effects of regularization\n",
    "        - num_iter: number of iteration\n",
    "        - alpha: learning rate\n",
    "    Outputs:\n",
    "        - X: updated X\n",
    "        - theta: updated theta\n",
    "        - J_hist: a list that collects the error between predicted and real rates in every iteration\n",
    "    \"\"\"\n",
    "    J_hist = []\n",
    "    for i in range(num_iter):\n",
    "        cost, grad = costfunction(X, y, r, theta, Lambda)\n",
    "        X = \n",
    "        theta = \n",
    "        J_hist.append(cost)\n",
    "        \n",
    "    return X, theta, J_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1be8c0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recommend a Movie For us\n",
    "#To recommend movies for us, we need to provide ratings for some moves.\n",
    "my_ratings = np.zeros((1682,1))\n",
    "my_ratings[5] = 5 \n",
    "my_ratings[50] = 1\n",
    "my_ratings[9] = 5\n",
    "my_ratings[27]= 4\n",
    "my_ratings[58] = 3\n",
    "my_ratings[88]= 2\n",
    "my_ratings[123]= 4\n",
    "my_ratings[165] = 1\n",
    "my_ratings[187]= 3\n",
    "my_ratings[196] = 2\n",
    "my_ratings[228]= 4\n",
    "my_ratings[258] = 5 \n",
    "my_ratings[343] = 4\n",
    "my_ratings[478] = 1\n",
    "my_ratings[511]= 4\n",
    "my_ratings[690] = 5\n",
    "my_ratings[722]= 1\n",
    "my_ratings[789]= 3\n",
    "my_ratings[832] = 2\n",
    "my_ratings[1029]= 4\n",
    "my_ratings[1190] = 2\n",
    "my_ratings[1245]= 5\n",
    "\n",
    "#We will add our ratings in the ‘y’ DataFrame now.\n",
    "y1 = np.hstack((my_ratings, y))\n",
    "\n",
    "# We also need to update r \n",
    "my_r = np.zeros((1682,1))\n",
    "for i in range(len(r)):\n",
    "    if my_ratings[i] !=0:\n",
    "        my_r[i] = 1\n",
    "r1 = np.hstack((my_r, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ef59d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let’s try to recommend movies for me using randomly initialized theta.\n",
    "num_users = y1.shape[1]\n",
    "num_movies = y1.shape[0]\n",
    "num_features = 10\n",
    "Theta1 = np.random.randn(num_users, num_features)\n",
    "x_up, theta_up, J_hist = gradientDescent(np.array(X), np.array(y1), np.array(r1), Theta1, 10, 500,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "168b937f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Cost function using Gradient Descent')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# So, we got the cost data for every iteration. Let’s plot it.\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(J_hist)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"$J(\\Theta)$\")\n",
    "plt.title(\"Cost function using Gradient Descent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec6a142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notice, we did not rate all the movies. \n",
    "#So, here using the updated parameters we will predict the ratings for all the movies for all the users.\n",
    "p = np.dot(x_up, theta_up.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cc35d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, our ratings were in the first column as we added using np.hstack. \n",
    "#Separate my ratings only and normalize it using the ‘ymean’ that came out from the ‘normalizeRatings’ function.\n",
    "def normalizeRatings(y, r):\n",
    "    ymean = np.sum(y, axis=1)/np.sum(r, axis=1)\n",
    "    ynorm = np.sum(y, axis=1)*np.sum(r, axis=1) - ymean\n",
    "    return ymean, ynorm\n",
    "ymean, ynorm = normalizeRatings(y1, r1)\n",
    "my_predictions = p[:, 0] + ymean\n",
    "my_predictions = pd.DataFrame(my_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf7d18bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, I will add these ratings to the movie list. First import the movie list.\n",
    "movies = open('movie_ids.txt', 'r',encoding='utf-8').read().split(\"\\n\")\n",
    "df = pd.DataFrame(np.hstack((my_predictions,np.array(movies)[:,np.newaxis])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c07968b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>5.0101143229808995</td>\n",
       "      <td>814 Great Day in Harlem, A (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>5.010071588890922</td>\n",
       "      <td>1500 Santa with Muscles (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>5.0088768121355045</td>\n",
       "      <td>1189 Prefontaine (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>5.0070972610739926</td>\n",
       "      <td>1201 Marlene Dietrich: Shadow and Light (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>5.001855099056595</td>\n",
       "      <td>1653 Entertaining Angels: The Dorothy Day Stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>5.001805157988351</td>\n",
       "      <td>1293 Star Kid (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>5.0010705252942165</td>\n",
       "      <td>1536 Aiqing wansui (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>5.000011503286801</td>\n",
       "      <td>1599 Someone Else's America (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>4.999123325635195</td>\n",
       "      <td>1122 They Made Me a Criminal (1939)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>4.998606614423978</td>\n",
       "      <td>1467 Saint of Fort Washington, The (1993)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0                                                  1\n",
       "813   5.0101143229808995                  814 Great Day in Harlem, A (1994)\n",
       "1499   5.010071588890922                     1500 Santa with Muscles (1996)\n",
       "1188  5.0088768121355045                            1189 Prefontaine (1997)\n",
       "1200  5.0070972610739926    1201 Marlene Dietrich: Shadow and Light (1996) \n",
       "1652   5.001855099056595  1653 Entertaining Angels: The Dorothy Day Stor...\n",
       "1292   5.001805157988351                               1293 Star Kid (1997)\n",
       "1535  5.0010705252942165                          1536 Aiqing wansui (1994)\n",
       "1598   5.000011503286801                 1599 Someone Else's America (1995)\n",
       "1121   4.999123325635195                1122 They Made Me a Criminal (1939)\n",
       "1466   4.998606614423978          1467 Saint of Fort Washington, The (1993)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We have the movie list and our ratings side by side now in a DataFrame. \n",
    "#If we just sort this DataFrame my_ratings, we will find the top-recommended movies for myself. \n",
    "#Here we get the top 10 recommended movies according to our ratings:\n",
    "df.sort_values(by=[0],ascending=False,inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8ab271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
